{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "enabling-arbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import json\n",
    "import pandas\n",
    "from pandas import DataFrame\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span\n",
    "from spacy import displacy\n",
    "from collections import defaultdict\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "from string import punctuation\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "satisfied-terrorist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hundred-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ld_json(url: str) -> dict:\n",
    "    parser = \"html.parser\"\n",
    "    req = requests.get(url)\n",
    "    page = soup(req.text, parser)\n",
    "    return json.loads(\"\".join(page.find(\"script\", {\"type\":\"application/ld+json\"}).contents))\n",
    "def get_ingredientScript(url):\n",
    "    jsonld = get_ld_json(url)\n",
    "    useful = jsonld[1]\n",
    "    ingredients = useful[\"recipeIngredient\"]\n",
    "    return ingredients\n",
    "def parse_ingredients(url):\n",
    "    ingredients = get_ingredientScript(url)\n",
    "    df = DataFrame (ingredients,columns=['ingredients'])\n",
    "    # 2 cases\n",
    "    # \"number\" (\"()\") (\"unit\") (adjective) \"noun/subject - ingredient\" (, other)\n",
    "    # contains \"to taste\"\n",
    "    df = df[\"ingredients\"]\n",
    "    df_taste = df[df.str.contains('to taste', case = False)]\n",
    "    \n",
    "    df_unit = df[~df.str.contains('to taste', case = False)]\n",
    "    \n",
    "    # array of arrays: each array is amount, unit, ingredient, descriptor, preparation\n",
    "    ingredients_parsed = []\n",
    "    \n",
    "    for i in df:\n",
    "        curr_arr = [\"\", \"\", \"\", \"\", \"\"]\n",
    "        print(i)\n",
    "        if 'to taste' not in i:\n",
    "        \n",
    "            # before we look at POS, remove everything after the comma and put it in prep\n",
    "            split_string = i.split(\", \", 1)\n",
    "            root_phrase = split_string[0]\n",
    "            if len(split_string) > 1:\n",
    "                other_piece = split_string[1]\n",
    "            else:\n",
    "                other_piece = \"\"\n",
    "\n",
    "            curr_arr[4] = other_piece\n",
    "\n",
    "            split_string2 = root_phrase.split(\"(\", 1)\n",
    "            if len(split_string2) > 1:\n",
    "                split_string3 = split_string2[1].split(\")\", 1)\n",
    "                curr_arr[3] = split_string3[0]\n",
    "                root_phrase = split_string2[0].strip() + split_string3[1]\n",
    "            doc = nlp(root_phrase)\n",
    "            index = 0\n",
    "            for token in doc:\n",
    "                found_num = False\n",
    "                # only get first number if it matches criteria\n",
    "                #if found_num == False and token.pos_ == \"NOUN\" and not token.is_alpha or token.pos_ == \"NUM\":\n",
    "                if index == 0:\n",
    "                    curr_arr[0] = token.text\n",
    "                elif index == 1:\n",
    "                    if token.pos_ != \"ADJ\":\n",
    "                        curr_arr[1] = token.text\n",
    "                    else:\n",
    "                        curr_arr[3] = token.text\n",
    "                elif token.dep_ == \"ROOT\":\n",
    "                    curr_arr[2] = token.text\n",
    "                else: \n",
    "                    curr_arr[3] = curr_arr[3] + \" \" + token.text\n",
    "                    curr_arr[3] = curr_arr[3].strip()\n",
    "                index+=1\n",
    "        else:\n",
    "            i = i.replace(\"to taste\", \"\")\n",
    "            doc = nlp(i)\n",
    "            curr_arr[0] = \"to taste\"\n",
    "            for token in doc:\n",
    "                if token.dep_ == \"ROOT\":\n",
    "                    curr_arr[2] = token.text\n",
    "                else:\n",
    "                    curr_arr[3] = curr_arr[3] + \" \" + token.text\n",
    "                    curr_arr[3] = curr_arr[3].strip()\n",
    "        ingredients_parsed.append(curr_arr)\n",
    "        #print(token.text, token.pos_, token.tag_, token.dep_, token.shape_, token.is_alpha, token.is_stop, token.children, token.head)\n",
    "        #displacy.render(doc, style=\"dep\") # change to serve when we go to python\n",
    "\n",
    "\n",
    "    \n",
    "    return ingredients_parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "auburn-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"https://www.allrecipes.com/recipe/257574\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "widespread-produce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-7243c82ad899>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mjson_ld\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ld_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-8fe3e6c9dff2>\u001b[0m in \u001b[0;36mget_ld_json\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mreq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"script\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"type\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"application/ld+json\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_ingredientScript\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mjsonld\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_ld_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "json_ld = get_ld_json(url1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "automotive-being",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 cups whole wheat flour\n",
      "½ cup packed brown sugar\n",
      "1 tablespoon baking powder\n",
      "1 teaspoon ground cinnamon\n",
      "½ teaspoon baking soda\n",
      "½ teaspoon salt\n",
      "½ teaspoon ground nutmeg\n",
      "1 (15 ounce) can solid-pack pumpkin\n",
      "½ cup water\n",
      "½ cup chocolate chips\n",
      "[['2', 'cups', '', 'whole wheat flour', ''], ['½', 'cup', 'sugar', 'packed brown', ''], ['1', 'tablespoon', 'powder', 'baking', ''], ['1', 'teaspoon', 'cinnamon', 'ground', ''], ['½', 'teaspoon', 'soda', 'baking', ''], ['½', 'teaspoon', 'salt', '', ''], ['½', 'teaspoon', 'nutmeg', 'ground', ''], ['1', 'can', '', '15 ounce solid - pack pumpkin', ''], ['½', 'cup', 'water', '', ''], ['½', 'cup', 'chips', 'chocolate', '']]\n"
     ]
    }
   ],
   "source": [
    "ing = parse_ingredients(url1)\n",
    "print(ing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "quick-seminar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mixture', 'ingredients', '2', 'cups', 'whole', 'wheat', 'flour', '½', 'cup', 'sugar', 'packed', 'brown', '1', 'tablespoon', 'powder', 'baking', 'teaspoon', 'cinnamon', 'ground', 'soda', 'salt', 'nutmeg', 'can', '15', 'ounce', 'solid', '-', 'pack', 'pumpkin', 'water', 'chips', 'chocolate', 'low-fat', 'vegan', 'chip', 'muffins']\n"
     ]
    }
   ],
   "source": [
    "one_list = itertools.chain.from_iterable(ing)\n",
    "fil = list(dict.fromkeys(one_list))\n",
    "new = ['mixture','ingredients']\n",
    "name = json_ld[1]['name']\n",
    "for ing in fil:\n",
    "    for word in ing.split():\n",
    "        new.append(word)\n",
    "for w in name.lower().split():\n",
    "    new.append(w)\n",
    "new = list(dict.fromkeys(new))\n",
    "print(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "unlikely-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preheat oven to 375 degrees F (190 degrees C). Line 12 muffin cups with paper liners.\n",
      "Whisk whole wheat flour, brown sugar, baking powder, cinnamon, baking soda, salt, and nutmeg in a large bowl. Stir pumpkin and water into dry ingredients, mixing until just moistened; fold in chocolate chips. Spoon batter into prepared muffin cups, filling them to just below the tops.\n",
      "Bake in the preheated oven until lightly browned and tops of muffins bounce back when pressed lightly, 25 to 30 minutes. Let muffins cool in pans for 5 minutes until removing to a wire rack to cool completely.\n",
      "\n",
      "Low-Fat Vegan Pumpkin Chocolate Chip Muffins\n"
     ]
    }
   ],
   "source": [
    "text = json_ld[1]['recipeInstructions']\n",
    "if len(text) > 1:\n",
    "    new_text = ''\n",
    "    for i,t in enumerate(text):\n",
    "        new_text = new_text + text[i]['text']\n",
    "    text = new_text\n",
    "else:\n",
    "    text = text[0]['text']\n",
    "print(text)\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "peripheral-cream",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 NUM nummod cups NOUN [] 2\n",
      "cups NOUN ROOT cups NOUN [2, flour] cup\n",
      "whole ADJ amod flour NOUN [] whole\n",
      "wheat NOUN compound flour NOUN [] wheat\n",
      "flour NOUN appos cups NOUN [whole, wheat] flour\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"5521d5f148ce43d0b77dcc25e0feb23e-0\" class=\"displacy\" width=\"925\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">2</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NUM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">cups</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">whole</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">wheat</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">flour</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5521d5f148ce43d0b77dcc25e0feb23e-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,177.0 215.0,177.0 215.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5521d5f148ce43d0b77dcc25e0feb23e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nummod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5521d5f148ce43d0b77dcc25e0feb23e-0-1\" stroke-width=\"2px\" d=\"M420,264.5 C420,89.5 745.0,89.5 745.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5521d5f148ce43d0b77dcc25e0feb23e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5521d5f148ce43d0b77dcc25e0feb23e-0-2\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5521d5f148ce43d0b77dcc25e0feb23e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,266.5 L587,254.5 603,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-5521d5f148ce43d0b77dcc25e0feb23e-0-3\" stroke-width=\"2px\" d=\"M245,264.5 C245,2.0 750.0,2.0 750.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-5521d5f148ce43d0b77dcc25e0feb23e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,266.5 L758.0,254.5 742.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp('2 cups whole wheat flour'.lower())\n",
    "for token in doc:\n",
    "    print(token.text,token.pos_, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children], token.lemma_)\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "brown-least",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 cups cups ROOT cups NOUN\n",
      "whole wheat flour flour appos cups NOUN\n"
     ]
    }
   ],
   "source": [
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, chunk.root.text, chunk.root.dep_,\n",
    "            chunk.root.head.text,chunk.root.head.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "moved-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tool(sentence):\n",
    "    pattern = [{\"LEMMA\":{\"IN\":['in','with']}},{\"POS\":'DET'},{\"POS\":'NOUN', 'OP':'+'}]\n",
    "    # tool_pattern = [{\"POS\":'NOUN', 'OP':'+'}]\n",
    "    tools = []\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add('find', [pattern])\n",
    "    doc = nlp(sentence)\n",
    "    matches = matcher(doc)\n",
    "    if len(matches) != 0:\n",
    "        span = doc[matches[-1][1]:matches[-1][2]]\n",
    "        for token in span:\n",
    "            if token.pos_ == 'NOUN':\n",
    "                tools.append(token)\n",
    "    return tools\n",
    "find_tool('Heat butter in a pan over medium heat')\n",
    "def find_tool2(sentence):\n",
    "    in_list = ['in','into','on','to']\n",
    "    too =[]\n",
    "    not_tools = []\n",
    "    sent = nlp(sentence.lower())\n",
    "    for chunk in sent.noun_chunks:\n",
    "#         and chunk.root.head.pos_ != 'VERB' and not chunk.root.is_sent_start\n",
    "        if chunk.root.text not in new and chunk.root.head.text in in_list:\n",
    "            too.append(chunk.root.text)\n",
    "#     for token in sent:\n",
    "#         if token.text not in too and token.pos_ == 'NOUN':\n",
    "#             not_tools.append(token.text)\n",
    "    return too, not_tools\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fallen-morgan",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preheat oven to 375 degrees F (190 degrees C).\n",
      "Line 12 muffin cups with paper liners.\n",
      "\n",
      "Whisk whole wheat flour, brown sugar, baking powder, cinnamon, baking soda, salt, and nutmeg in a large bowl.\n",
      "bowl\n",
      "Stir pumpkin and water into dry ingredients, mixing until just moistened; fold in chocolate chips.\n",
      "Spoon batter into prepared muffin cups, filling them to just below the tops.\n",
      "\n",
      "Bake in the preheated oven until lightly browned and tops of muffins bounce back when pressed lightly, 25 to 30 minutes.\n",
      "oven\n",
      "Let muffins cool in pans for 5 minutes until removing to a wire rack to cool completely.\n",
      "\n",
      "pans\n",
      "rack\n",
      "['bowl', 'oven', 'pans', 'rack']\n"
     ]
    }
   ],
   "source": [
    "tools = []\n",
    "\n",
    "for sentence in nlp(text).sents:\n",
    "    print(sentence)\n",
    "    t,nt = find_tool2(str(sentence))\n",
    "    for each in t:\n",
    "        print(each)\n",
    "#         if each not in big_not_tools:\n",
    "        tools.append(each)\n",
    "print(tools)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-security",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-validity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
